{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ![alt text](https://gluon-cv.mxnet.io/_static/gluon-logo.svg \"Gluon Logo\")\n",
    "  \n",
    "  #  GluonCV: a Deep Learning Toolkit for Computer Vision\n",
    "\n",
    "GluonCV provides implementations of state-of-the-art (SOTA) deep learning algorithms in computer vision. It aims to help engineers, researchers, and students quickly prototype products, validate new ideas and learn computer vision.\n",
    "\n",
    "GluonCV features:\n",
    "\n",
    "   * training scripts that reproduce SOTA results reported in latest papers,\n",
    "\n",
    "   * a large set of pre-trained models,\n",
    "\n",
    "   * carefully designed APIs and easy to understand implementations,\n",
    "\n",
    "   * community support.\n",
    "\n",
    "   \n",
    "![alt text](images/gluoncv.png \"Gluoncv Applications\")\n",
    "\n",
    "This notebook will focus on training a <b>custom Object Detection model</b> using the <b>SSD</b> network\n",
    "(custom means we are not using a pre-trained model trained on a dataset such as ImageNet)\n",
    "\n",
    "In order to use the GluonCV library, we must install it by updating the version of mxnet that is installed.\n",
    "We will also update some paths to the CUDA libraries, a dependency of GluonCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# The following lines install GluonCV onto our Notebook instance.  \n",
    "# While we are *NOT* training on this instance we want GluonCV installed to explore the API\n",
    "!export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/cuda-10.0/lib64/\n",
    "!export PATH=/usr/local/cuda-10.0/bin${PATH:+:${PATH}}\n",
    "!pip install mxnet-cu101\n",
    "!pip install --upgrade mxnet-cu101 gluoncv\n",
    "!sudo yum install tree -y # <-- Assumes we are running on a Sagemaker Notebook instance and using Amazon Linux\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3                            # AWS Python framework                            \n",
    "import os                               # OS library to access file paths\n",
    "from gluoncv import data, utils         # gluoncv data and utils modules to create datasets\n",
    "from gluoncv.data import VOCDetection   # VOCDetection allows gluoncv to recognize our boundingboxes and classes\n",
    "from gluoncv.utils import viz           # gluoncv specific visualization capabilities\n",
    "from matplotlib import pyplot as plt    # visualization capabilites (to view dataset samples)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   We are going to use a PASCAL VOC formatted dataset for this model.  We will briefly cover the formatting of a VOC Dataset in this notebook, but for more information about PASCAL VOC, visit: https://gluon-cv.mxnet.io/build/examples_datasets/pascal_voc.html#sphx-glr-build-examples-datasets-pascal-voc-py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Move sample data from S3 to our notebook instance\n",
    "We have a small sample dataset that we will evaluate on this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp --recursive s3://gluoncv-notebook ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us take a look a the directory structure of a typical PASCAL VOC dataset:\n",
    "!tree VOC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this example, we will use the images and annotations in \"VOCvalidate\" as our validation dataset and the images and annotations in \"VOCtrain\" as our training dataset.  The \"VOCvalidate\" folder could be named anything meaningful. In this example since we have only 1 training and 1 validation dataset we keep the names simple and refer to them as VOCtrain and VOCvalidate, but we will see momentarily why the folders \"VOCvalidate\" & \"VOCtrain\" are not synonymous with datasets, instead we will refer to them as VOC Imageset folders. \n",
    "\n",
    "**note** The word VOC must be the first three letters of the ImageSet foldernames or the VOCDetection method that will be introduced later will not recognize the folders.\n",
    "\n",
    "Within each VOC Imageset folder there are 3 child folders:\n",
    "    Annotations\n",
    "    ImageSets\n",
    "    JPEGImages\n",
    "    \n",
    "The <b>Annotations<b> folder holds .XML files.  Each XML file contains bounding box information for 1 image file in the dataset. That image file may have multiple objects, but there is a 1:1 relationship between annotation files and imamge files.  Let's look at one of the Annotation files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat VOC/VOCvalidate/Annotations/aug3_046386182.xml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above annotation file, there are 4 object nodes.  The image (which we will see soon, contains two playing cards. Each playing card has two locations for rank and suite and in this image, all 4 locations are visible.\n",
    "\n",
    "Each object node contains the class name (QC, 8H) as well as the bounding box for the rank and suite. It is important to note the this model ONLY detects the rank and suite of playing cards, not the entire card or the number of suite icons on the card."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second child folder is ImageSets. This folder contains text files that list the images you wish to include in a particular dataset. Lets take a look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat VOC/VOCvalidate/ImageSets/Main/val.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When dealing with a VOC dataset for object detection, we use a child folder called \"Main\" within the ImageSets folder.  If we were using gluoncv for other task such as Action/Event, Pose Detection or Segmentation we would create additional folders at the level of Main and give them names corresponding to the type of model. Within the Main folder is a file called val.txt. It is used to encapsulate the size of the dataset we wish to use by listing each image name. In this example, we only include 5 files.  You will note the file extension is absent.  The PASCAL VOC format will expect to find an annotation file (In the Annotation directory and ending in .xml) of the same name as each entry in this val.txt.  PASCAL VOC will also expect to find an image file of the same name in the JPEGImages directory with a .jpg extension.\n",
    "\n",
    "This structure allows you to store n files in the annotations and JPEGImages directories, and then customize an ImageSet listing file to only train/validate on selected annotation and JPEGImage files.  This gives you the capability to store as many images as you wish in a single directory, but create separate datasets by creating multiple ImageSet files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final directory is the JPEGImages folder which as stated above, contains the corresponding image to the annotations file. We will use the GluonCV API to explore these files further, first however we need to introduce gluoncv to our class structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dataset has <b>52 classes</b> - corresponding to the 52 different cards in a deck of playing cards (minus the Jokers)\n",
    "![alt text](images/playingcards.png \"Deck of cards\")\n",
    "\n",
    "The class names are abbreviated by first letter of rank and first letter of suite:\n",
    "\n",
    "    2C = Two of Clubs\n",
    "    AS = Ace of Spades\n",
    "    ...\n",
    "\n",
    "We will create a class derived from the VOCDetection method for our custom dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VOCLike(VOCDetection):\n",
    "    #CLASSES = [\"ac\", \"2c\", \"3c\", \"4c\", \"5c\", \"6c\", \"7c\", \"8c\", \"9c\", \"10c\", \"jc\", \"qc\", \"kc\", \"ad\", \"2d\", \"3d\", \"4d\", \"5d\", \"6d\", \"7d\", \"8d\", \"9d\", \"10d\", \"jd\", \"qd\", \"kd\", \"ah\", \"2h\", \"3h\", \"4h\", \"5h\", \"6h\", \"7h\", \"8h\", \"9h\", \"10h\", \"jh\", \"qh\", \"kh\", \"as\", \"2s\", \"3s\", \"4s\", \"5s\", \"6s\", \"7s\", \"8s\", \"9s\", \"10s\", \"js\", \"qs\", \"ks\"]\n",
    "    CLASSES = [\"boxwrench\", \"crafthammer\", \"crescent_wrench\"]\n",
    "    def __init__(self, root, splits, transform=None, index_map=None, preload_label=True):\n",
    "        super(VOCLike, self).__init__(root, splits, transform, index_map, preload_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gluoncv.utils.metrics.voc_detection import VOC07MApMetric\n",
    "\n",
    "# Use our newly created class to generate a reference to the training data\n",
    "train_dataset = VOCLike(root='VOCTemplate', splits=(('VOCTrain', 'train'),))\n",
    "    \n",
    "# Use our newly created class to generate a reference to the validation data\n",
    "val_dataset = VOCLike(root='VOCTemplate', splits=(('VOCValid', 'valid'),))\n",
    "\n",
    "# This metric will be introduced later prior to training\n",
    "val_metric = VOC07MApMetric(iou_thresh=0.5, class_names=val_dataset.classes)\n",
    "\n",
    "print('Training images:', len(train_dataset))\n",
    "print('Validation images:', len(val_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though our label (annotation + classname) data is currently in a separate file from our image.  We can use the GluonCV library to read an image-label pair:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a training image and corresponding label\n",
    "train_image, train_label = train_dataset[24000]\n",
    "\n",
    "\n",
    "# The train_image is an mxnet.ndarray that should be a 720 x 720 RGB image\n",
    "print(\"train_image shape:{}\".format(train_image.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we will take a moment to pay special attention to the shape of the train_label\n",
    "\n",
    "# the label is a numpy array \n",
    "print(\"train_label type: {}\".format(type(train_label)))\n",
    "\n",
    "# the array has n elements - 1 element for each object in the train image\n",
    "print(\"train_label shape: {}\".format(train_label.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets look at the entire array:\n",
    "print(train_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first 4 positions in an element are the bounding box (xmin, ymin, xmax, ymax)\n",
    "The 5th position is the class ID\n",
    "The 6th position is the label, if it has been pre-loaded\n",
    "\n",
    "![alt text](images/label_shape.png \"Label shape\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's view this image with bounding boxes and classes\n",
    "bboxes = train_label[:, :4]   # Get all elements :, and get all positions up to the 4th :4\n",
    "cids = train_label[:, 4:5]    # Get the class ID in the 4th position\n",
    "print('image:', train_image.shape)\n",
    "print('bboxes:', bboxes.shape, 'class ids:', cids.shape)\n",
    "ax = viz.plot_bbox(train_image.asnumpy(), bboxes, labels=cids, class_names=train_dataset.classes)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker-us-east-1-056149205531\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "from sagemaker.mxnet import MXNet\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = get_execution_role()\n",
    "\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "model_artifacts_location = 's3://{}/artifacts'.format(bucket)\n",
    "\n",
    "print(bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "estimator = MXNet(entry_point=\"train_ssd-playing-cards.py\",\n",
    "          role=role,\n",
    "          output_path=model_artifacts_location,\n",
    "          train_instance_count=1,\n",
    "          train_instance_type=\"ml.p3.16xlarge\",\n",
    "          framework_version=\"1.6.0\",\n",
    "          py_version=\"py3\",\n",
    "          train_max_run=172800)\n",
    "\n",
    "#!python train_ssd-playing-cards.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-01 11:18:55 Starting - Starting the training job...\n",
      "2020-05-01 11:18:57 Starting - Launching requested ML instances.........\n",
      "2020-05-01 11:20:30 Starting - Preparing the instances for training......\n",
      "2020-05-01 11:21:32 Downloading - Downloading input data..............................................................................\n",
      "2020-05-01 11:34:42 Training - Downloading the training image.\u001b[34m2020-05-01 11:35:04,915 sagemaker-containers INFO     Imported framework sagemaker_mxnet_container.training\u001b[0m\n",
      "\u001b[34m2020-05-01 11:35:04,998 sagemaker_mxnet_container.training INFO     MXNet training environment: {'SM_HOSTS': '[\"algo-1\"]', 'SM_NETWORK_INTERFACE_NAME': 'eth0', 'SM_HPS': '{}', 'SM_USER_ENTRY_POINT': 'train_ssd-playing-cards.py', 'SM_FRAMEWORK_PARAMS': '{}', 'SM_RESOURCE_CONFIG': '{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}', 'SM_INPUT_DATA_CONFIG': '{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}', 'SM_OUTPUT_DATA_DIR': '/opt/ml/output/data', 'SM_CHANNELS': '[\"training\"]', 'SM_CURRENT_HOST': 'algo-1', 'SM_MODULE_NAME': 'train_ssd-playing-cards', 'SM_LOG_LEVEL': '20', 'SM_FRAMEWORK_MODULE': 'sagemaker_mxnet_container.training:main', 'SM_INPUT_DIR': '/opt/ml/input', 'SM_INPUT_CONFIG_DIR': '/opt/ml/input/config', 'SM_OUTPUT_DIR': '/opt/ml/output', 'SM_NUM_CPUS': '64', 'SM_NUM_GPUS': '8', 'SM_MODEL_DIR': '/opt/ml/model', 'SM_MODULE_DIR': 's3://sagemaker-us-east-1-056149205531/mxnet-training-2020-05-01-11-18-54-786/source/sourcedir.tar.gz', 'SM_TRAINING_ENV': '{\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_mxnet_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"mxnet-training-2020-05-01-11-18-54-786\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-056149205531/mxnet-training-2020-05-01-11-18-54-786/source/sourcedir.tar.gz\",\"module_name\":\"train_ssd-playing-cards\",\"network_interface_name\":\"eth0\",\"num_cpus\":64,\"num_gpus\":8,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train_ssd-playing-cards.py\"}', 'SM_USER_ARGS': '[]', 'SM_OUTPUT_INTERMEDIATE_DIR': '/opt/ml/output/intermediate', 'SM_CHANNEL_TRAINING': '/opt/ml/input/data/training'}\u001b[0m\n",
      "\u001b[34m2020-05-01 11:35:05,378 sagemaker-containers INFO     Module default_user_module_name does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m2020-05-01 11:35:05,378 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[34m2020-05-01 11:35:05,378 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m2020-05-01 11:35:05,378 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/usr/local/bin/python3.6 -m pip install . \u001b[0m\n",
      "\u001b[34mProcessing /tmp/tmpvbyk_5ur/module_dir\u001b[0m\n",
      "\u001b[34mInstalling collected packages: default-user-module-name\n",
      "    Running setup.py install for default-user-module-name: started\u001b[0m\n",
      "\u001b[34m    Running setup.py install for default-user-module-name: finished with status 'done'\u001b[0m\n",
      "\u001b[34mSuccessfully installed default-user-module-name-1.0.0\u001b[0m\n",
      "\u001b[34mWARNING: You are using pip version 19.3.1; however, version 20.1 is available.\u001b[0m\n",
      "\u001b[34mYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[34m2020-05-01 11:35:07,698 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_mxnet_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {},\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"mxnet-training-2020-05-01-11-18-54-786\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-056149205531/mxnet-training-2020-05-01-11-18-54-786/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train_ssd-playing-cards\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 64,\n",
      "    \"num_gpus\": 8,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train_ssd-playing-cards.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train_ssd-playing-cards.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train_ssd-playing-cards\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_mxnet_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=64\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=8\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-056149205531/mxnet-training-2020-05-01-11-18-54-786/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_mxnet_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"mxnet-training-2020-05-01-11-18-54-786\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-056149205531/mxnet-training-2020-05-01-11-18-54-786/source/sourcedir.tar.gz\",\"module_name\":\"train_ssd-playing-cards\",\"network_interface_name\":\"eth0\",\"num_cpus\":64,\"num_gpus\":8,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train_ssd-playing-cards.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/local/lib/python36.zip:/usr/local/lib/python3.6:/usr/local/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/usr/local/bin/python3.6 train_ssd-playing-cards.py\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"train_ssd-playing-cards.py\", line 301, in <module>\n",
      "    hvd.init()\u001b[0m\n",
      "\u001b[34mNameError: name 'hvd' is not defined\u001b[0m\n",
      "\u001b[34m2020-05-01 11:35:10,980 sagemaker-containers ERROR    ExecuteUserScriptError:\u001b[0m\n",
      "\u001b[34mCommand \"/usr/local/bin/python3.6 train_ssd-playing-cards.py\"\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"/usr/local/bin/dockerd-entrypoint.py\", line 20, in <module>\n",
      "    subprocess.check_call(shlex.split(' '.join(sys.argv[1:])))\n",
      "  File \"/usr/local/lib/python3.6/subprocess.py\", line 311, in check_call\n",
      "    raise CalledProcessError(retcode, cmd)\u001b[0m\n",
      "\u001b[34msubprocess.CalledProcessError: Command '['train']' returned non-zero exit status 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2020-05-01 11:35:16 Uploading - Uploading generated training model\n",
      "2020-05-01 11:35:16 Failed - Training job failed\n"
     ]
    },
    {
     "ename": "UnexpectedStatusException",
     "evalue": "Error for Training job mxnet-training-2020-05-01-11-18-54-786: Failed. Reason: AlgorithmError: ExecuteUserScriptError:\nCommand \"/usr/local/bin/python3.6 train_ssd-playing-cards.py\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-26462f36a162>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#estimator.fit(\"s3://gluoncv-training/VOC-PlayingCards\", wait=False)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"s3://gluoncv-training/VOC-PlayingCards\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, inputs, wait, logs, job_name, experiment_config)\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_compilation_job_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0;31m# If logs are requested, call logs_for_jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1085\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlogs\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"None\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1086\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogs_for_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1087\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1088\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mlogs_for_job\u001b[0;34m(self, job_name, wait, poll, log_type)\u001b[0m\n\u001b[1;32m   3042\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3043\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3044\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_job_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"TrainingJobStatus\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3045\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdot\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3046\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36m_check_job_status\u001b[0;34m(self, job, desc, status_key_name)\u001b[0m\n\u001b[1;32m   2636\u001b[0m                 ),\n\u001b[1;32m   2637\u001b[0m                 \u001b[0mallowed_statuses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Completed\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Stopped\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2638\u001b[0;31m                 \u001b[0mactual_status\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2639\u001b[0m             )\n\u001b[1;32m   2640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m: Error for Training job mxnet-training-2020-05-01-11-18-54-786: Failed. Reason: AlgorithmError: ExecuteUserScriptError:\nCommand \"/usr/local/bin/python3.6 train_ssd-playing-cards.py\""
     ]
    }
   ],
   "source": [
    "#estimator.fit(\"s3://gluoncv-training/VOC-PlayingCards\", wait=False)\n",
    "estimator.fit(\"s3://gluoncv-training/VOC-PlayingCards\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = '/'.join(estimator.output_path.split('/')[:-1])\n",
    "compiled_model = estimator.compile_model(target_instance_family='inf1', \n",
    "                                               input_shape={'data':[1, 1, 512, 512]},\n",
    "                                               role=role,\n",
    "                                               output_path=output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = compiled_model.deploy(initial_instance_count = 1, instance_type = 'ml.inf1.2xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debug Cell - Don't publish\n",
    "import mxnet as mx\n",
    "from gluoncv.model_zoo import get_model\n",
    "from mxnet.gluon.model_zoo import vision\n",
    "\n",
    "\n",
    "klasses = [\"ac\", \"2c\", \"3c\", \"4c\", \"5c\", \"6c\", \"7c\", \"8c\", \"9c\", \"10c\", \"jc\", \"qc\", \"kc\", \"ad\", \"2d\", \"3d\", \"4d\", \"5d\",\n",
    "           \"6d\", \"7d\", \"8d\", \"9d\", \"10d\", \"jd\", \"qd\", \"kd\", \"ah\", \"2h\", \"3h\", \"4h\", \"5h\", \"6h\", \"7h\", \"8h\", \"9h\", \"10h\",\n",
    "           \"jh\", \"qh\", \"kh\", \"as\", \"2s\", \"3s\", \"4s\", \"5s\", \"6s\", \"7s\", \"8s\", \"9s\", \"10s\", \"js\", \"qs\", \"ks\"]\n",
    "\n",
    "num_classes = [str(x) for x in range(len(klasses)+1)]\n",
    "\n",
    "# GluonCV\n",
    "net = get_model(\"yolo3_mobilenet1.0_custom\", classes = num_classes, ctx=mx.gpu(0))\n",
    "net.load_parameters('yolo3_mobilenet1.0_custom_best.params', ctx=mx.gpu(0))\n",
    "net.collect_params().reset_ctx(mx.gpu(0))\n",
    "\n",
    "# MXNET\n",
    "mnet = vision.MobileNet(classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
